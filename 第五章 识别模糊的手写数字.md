# 第五章 识别图中模糊的手写数字
实例描述：从MNIST数据集中选择一幅图，让机器模拟人眼 区分数字到是几

代码编写步骤：

1.导入MNIST数据集

2.分析MNIST样本特点，定义变量

3.构建模型 【这个模型很简单，仅使用了一个神经元——Softmax Regression】

4.训练模型并输出中间状态参数

5.测试模型

6.保存模型

7.读取模型

## 5.1 导入MNIST数据集
MNIST数据集是一个计算机视觉入门级的数据集，里面包含各种手写数字图片。

MNIST数据集中图片是28x28 Pixel,因此，每一幅图就是【1行784列】的数据，（28*28=784）

黑白图片，黑色地方数值为0，有图案的地方数值为0~255之间的数字，代表其颜色的深度。


```python
#下载并安装MNIST数据集到指定文件夹下，并将样本标签转化为one_hot编码
from tensorflow.examples.tutorials.mnist import input_data
mnist=input_data.read_data_sets('H:\DeepLearning\BOOK_TensorFlowForDeepLearning\MNIST_data',one_hot=True)
```

    WARNING:tensorflow:From <ipython-input-15-fbd7b682dac6>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
    Instructions for updating:
    Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
    WARNING:tensorflow:From d:\python\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
    Instructions for updating:
    Please write your own downloading logic.
    WARNING:tensorflow:From d:\python\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
    Instructions for updating:
    Please use tf.data to implement this functionality.
    Extracting H:\DeepLearning\BOOK_TensorFlowForDeepLearning\MNIST_data\train-images-idx3-ubyte.gz
    WARNING:tensorflow:From d:\python\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
    Instructions for updating:
    Please use tf.data to implement this functionality.
    Extracting H:\DeepLearning\BOOK_TensorFlowForDeepLearning\MNIST_data\train-labels-idx1-ubyte.gz
    WARNING:tensorflow:From d:\python\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
    Instructions for updating:
    Please use tf.one_hot on tensors.
    Extracting H:\DeepLearning\BOOK_TensorFlowForDeepLearning\MNIST_data\t10k-images-idx3-ubyte.gz
    Extracting H:\DeepLearning\BOOK_TensorFlowForDeepLearning\MNIST_data\t10k-labels-idx1-ubyte.gz
    WARNING:tensorflow:From d:\python\lib\site-packages\tensorflow\contrib\learn\python\learn\datasets\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
    Instructions for updating:
    Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
    


```python
print("输入数据：",mnist.train.images)
print("输入数据维度：",mnist.train.images.shape)  #说明训练集中有55000张图片
```

    输入数据： [[0. 0. 0. ... 0. 0. 0.]
     [0. 0. 0. ... 0. 0. 0.]
     [0. 0. 0. ... 0. 0. 0.]
     ...
     [0. 0. 0. ... 0. 0. 0.]
     [0. 0. 0. ... 0. 0. 0.]
     [0. 0. 0. ... 0. 0. 0.]]
    输入数据维度： (55000, 784)
    


```python
import pylab
im=mnist.train.images[1]  #看一下第一张图片啥样
im=im.reshape(-1,28)
pylab.imshow(im)
pylab.show()
```


![png](output_4_0.png)


MNIST里包含3个数据集，第一个是训练数据集mnist.train.images，我们已经知道它是一个形状为[55000,784] 的张量

再看一下测试集和验证集的数据：


```python
print("测试集维度：",mnist.test.images.shape)
print("验证集维度：",mnist.validation.images.shape)
```

    测试集维度： (10000, 784)
    验证集维度： (5000, 784)
    

总的来说，训练集55000张、测试集10000张、验证集5000张，MNIST一共有7万张图片

相应的，每张图片还对应有自己的标签文件，标签是介于0~9之间的数字，我们已将其改为独热码来表示。例如，标签0将被表示为（[1,0,0,0,0,0,0,0,0]）,因此mnist.train.labels是一个[55000,10]的数字矩阵

## 5.2 分析图片特点，定义变量


```python
import tensorflow as tf
import pylab
tf.reset_default_graph()

#定义占位符
x=tf.placeholder(tf.float32,[None,784])
y=tf.placeholder(tf.float32,[None,10])
```

由于输入图片是一个55000x784的矩阵，输入标签是一个55000x10的矩阵，因此我们创建[None,784]的占位符x，和[None,10]的占位符y,后续使用feed机制将图片和标签输进去。之所以使用None是因为这样此张量的第一个维度就可以是任意长度的，x就能代表任意数量的MNIST图像，并将每张图像展平成784维向量

## 5.3 构建模型
### 5.3.1 定义学习参数
TensorFlow中使用Variable来定义学习参数，定义好的参数可以用于计算输入值、也可以在计算中被修改



```python
# 定义学习参数
w=tf.Variable(tf.random_normal([784,10]))
b=tf.Variable(tf.zeros([10]))
```

备注：定义学习参数时，一般将w设为一个随机值，b设为0.

这里将w的维度设置为784x10是因为，我们要用784维的图片向量和它相乘，得到一个10维的输出向量.将b维度设置10是因为，b是可以直接加到输出上面的值，所以b的形状要和输出保持一致.

### 5.3.2 定义输出节点
将输入和模型参数串起来构建成真正的模型，这也是正向传播模型


```python
#定义输出节点
pred=tf.nn.softmax(tf.matmul(x,w)+b)    #使用softmax分类
```

### 5.3.3 定义反向传播结构


```python
#定义反向传播结构

#损失函数
cost=tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred),reduction_indices=1))  # pred 与 y 进行交叉熵运算，取平均值
#学习率
learning_rate=0.01
#梯度下降优化
optimizer=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)
```

## 5.4 训练模型并输出中间状态参数


```python
# training_epoch表示把整个训练集迭代的次数
# batch_size 表示训练过程中每次取多少条数据进行训练。深度学习中，数据并非一次性放入，而是分批次放的！
# display_step 表示每训练多少次就把中间状态显示出来
training_epochs=25
batch_size=100
display_step=1
```


```python
saver=tf.train.Saver()

# 启动session
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    
#     设置循环，开始训练
    for epoch in range(training_epochs):
        avg_cost=0.
        total_batch=int(mnist.train.num_examples/batch_size)
        #循环所有数据集
        for i in range(total_batch):
            batch_xs,batch_ys=mnist.train.next_batch(batch_size)
            #运行优化器
            _,c=sess.run([optimizer,cost],feed_dict={x:batch_xs,y:batch_ys})
            #平均损失值
            avg_cost+=c/total_batch
            
        #显式训练中的详细信息
        if (epoch+1)% display_step == 0:
            print("Epoch:",'%04d'%(epoch+1),"cost=","{:.9f}".format(avg_cost))
        
    print("Finished!")
    
    #测试模型
    correct_prediction=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))   #tf.argmax返回独热码中值为1的元素的下标
    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))
    print("Accuracy:",accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))
    
    #保存模型
    saver.save(sess,"H:\DeepLearning\BOOK_TensorFlowForDeepLearning\MNIST_Model\521model.ckpt")
```

    Epoch: 0001 cost= 8.407759780
    Epoch: 0002 cost= 4.777937721
    Epoch: 0003 cost= 3.369093680
    Epoch: 0004 cost= 2.642504473
    Epoch: 0005 cost= 2.210864716
    Epoch: 0006 cost= 1.927795367
    Epoch: 0007 cost= 1.728733199
    Epoch: 0008 cost= 1.581676434
    Epoch: 0009 cost= 1.468613322
    Epoch: 0010 cost= 1.379000230
    Epoch: 0011 cost= 1.305861450
    Epoch: 0012 cost= 1.245085007
    Epoch: 0013 cost= 1.193424019
    Epoch: 0014 cost= 1.148958449
    Epoch: 0015 cost= 1.110289388
    Epoch: 0016 cost= 1.075845395
    Epoch: 0017 cost= 1.045519968
    Epoch: 0018 cost= 1.017877299
    Epoch: 0019 cost= 0.993278026
    Epoch: 0020 cost= 0.970528116
    Epoch: 0021 cost= 0.949855853
    Epoch: 0022 cost= 0.930762983
    Epoch: 0023 cost= 0.913097514
    Epoch: 0024 cost= 0.896743715
    Epoch: 0025 cost= 0.881435040
    Finished!
    Accuracy: 0.8275
    

## 5.5 测试模型、5.6 保存模型
这两个过程均添加在上一级代码中，因为这两个过程仍然是在session中运行的。
## 5.7 读取模型
读取模型，并在新的session中运行


```python
import tensorflow as tf
import pylab
import numpy as np

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    new_saver = tf.train.import_meta_graph("H:/DeepLearning/BOOK_TensorFlowForDeepLearning/MNIST_Model/"+"MNIST_Modelmodel.ckpt.meta")
    new_saver.restore(sess,"H:/DeepLearning/BOOK_TensorFlowForDeepLearning/MNIST_Model/"+"MNIST_Modelőmodel.ckpt")   
    
    correct_prediction=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))
    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))
    print("Accuracy:",accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))
    
    output=tf.argmax(pred,1)
    batch_xs,batch_ys=mnist.train.next_batch(2)
    outputval,predv=sess.run([output,pred],feed_dict={x:batch_xs})
    print(outputval,predv,batch_ys)
    
    im=batch_xs[0]
    im=im.reshape(-1,28)
    pylab.imshow(im)
    pylab.show()
    
    im=batch_xs[1]
    im=im.reshape(-1,28)
    pylab.imshow(im)
    pylab.show() 
```

    INFO:tensorflow:Restoring parameters from H:/DeepLearning/BOOK_TensorFlowForDeepLearning/MNIST_Model/MNIST_Modelőmodel.ckpt
    Accuracy: 0.826
    [0 7] [[7.7076638e-01 8.3779577e-07 3.7823238e-06 2.2741272e-03 2.2476169e-01
      8.6059520e-04 2.7897954e-04 1.6411570e-06 1.0504072e-03 1.6575611e-06]
     [6.4199558e-05 2.3884268e-11 4.3123616e-11 1.0466332e-04 7.7985213e-05
      1.3495362e-01 4.7170906e-07 8.6107504e-01 2.9784304e-03 7.4549607e-04]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
     [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]
    


![png](output_21_1.png)



![png](output_21_2.png)


测试模型最易出错的部分：文件路径的读取，用左斜杠比较好，在文件夹里直接复制的路径是右斜杠，容易出错：【SyntaxError: EOL while scanning string literal】


```python

```
